# AlgorithmicTrader

## Introduction
This is a project created by Elias Izmirlian, and aims to classify whether a stock's closing price will go up by at least 1% or not in three days. The stock market has always been considered a tough problem for AI systems to tackle due to its complex and volatile nature. There is a massive number of factors which influence price movements in the stock market, so the capabilities of a stochastic model in modeling these movements are limited. However, if the stock market is truly random as the Random Walk Theory describes, meaning historical prices have no influence on current prices, then the collective of people making investing decisions which drive the market must be making decisions purely randomly, which we know to be untrue. With the capabilities of modern AI, there are multiple methods of information capture and analyses which could serve to simplify the human thought that often dictates the market. I wanted to simplify the problem of predicting price movement as much as possible, therefore I aimed to model short term changes as they were easier to observe, but wanted a prediction window of at least a few days because these price movements are less likely to be as erratic as single-day changes. I also decided that trying to classify stocks as having any upwards or downwards movement in closing price three days into the future was too difficult, as then the classifier would need to be sensitive to very minute changes.
Note that I do not recommend using this system in order to make financial traiding decisions, it is more of a test of the capabilities of some of the modern AI tools at our disposal. While the initial results have shown some promise (around 70% accuracy on the small group of stocks I have tested it on), further testing is required to determine with what accuracy the system can be sensitive to stocks with incoming upwards price movement.

## Libraries Used
This project makes use of pytorch, sklearn, yfinance, openai, BeautifulSoup4, numpy, pandas, joblib, matplotlib, and some built-in python libraries such as datetime, csv, time, json, math, and statistics

## Three Layers of Analyses
When explaining how this system makes classification decisions/predictions, I would break it down into three layers. First, there is a pytorch bidirectional LSTM model which is trained on individual stocks. The specifics of the model are defined in lstm_toolkit.py. Recently trained models are saved in the lstm_models directory in order to save on the time it would take to retrain them. The models are trained in lstm.py, and the training and storing models is handled by lstm_controller.py. These LSTM models are trained on 5 years worth of stock closing price history, which is formatted so an 80 day window of closing prices is given as input, and the closing price of the day directly after the window is the expected ouput. The trained models are then used to generate three days of predictions (with the latter two days using predicted closing prices as an input). The methods responsible for generating predictions is also in lstm.py - these methods leverage MonteCarlo Dropout in order to get a more averaged and stable prediction. 
The second layer is sentiment analysis. Most of the work my system does for this portion is webscraping financial news. The financial news is pulled from Bloomberg and Charles Schwab Market Updates using BeautifulSoup4 as an html parser. Market-wide news and stock specific news are pulled from the Schwab Market Update, while Bloombeg financial news is used only for stock specific news. Once relevamt news has been scraped and cleaned, it is passed to openAI's chatgpt-3.5-turbo model and is prompted to act as a sentiment analyzer for financial news, with certain specifications ensuring the outputted message is in the correct format. Note that I had the free version of access to openAPI's chatGPT, which comes with the restriction of making requests no more than 3 times per minute. Due to this restriction, I had to put in stops where the program would wait for 60 seconds in order to avoid getting an error response from openai. However, collected scores are saved in respective jsons for market scores and stock-specific scores, so this does not need to be run multiple times for the same dates.
The final layer of analysis is purely statistical - helper_stats.py contains a number of methods to return values like momentum, volatility, bollinger highs/lows based on the ten-day price history. This file is also responsible for labeling datapoints for the SVM.

These three layers are used to glean different forms of information from multiple sources, and all this information is assembled into an input vector for an sklearn SVM to classify. The data which the SVM is fit on is generated in svm_data_generation.py. This file also facilitates collecting sentiment scores.